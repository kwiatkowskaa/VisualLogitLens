{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dad196",
   "metadata": {},
   "source": [
    "## Note on the Functioning of Logit Lens\n",
    "\n",
    "This note is based on the article [Interpreting GPT: The Logit Lens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens#other_examples).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef3ef2",
   "metadata": {},
   "source": [
    "## What is Logit Lens?\n",
    "\n",
    "*Logit Lens* is used for analyzing the functioning of language models like GPT. Instead of focusing on **how** the model processes data, *Logit Lens* allows us to examine **what** the model predicts as the next token at various stages of text generation. This helps to understand **what the model \"thinks\" during its operation**.\n",
    "\n",
    "With *Logit Lens*, we can:\n",
    "- Peek inside the model and see which words it considers at different layers,\n",
    "- Check how early the model begins to \"guess\" what word should appear next — often, by the middle of processing, the model already has accurate predictions about the next token,\n",
    "- Trace how these predictions change across subsequent layers until the final output.\n",
    "\n",
    "However, it's important to note that *Logit Lens* shows **only one aspect of the model's operation** – its predictions at various stages. It doesn't answer questions like:\n",
    "\n",
    "- **How** does the model arrive at these predictions,\n",
    "- What other information (e.g., intermediate representations, rules, structures) is stored and processed in the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0395aca",
   "metadata": {},
   "source": [
    "## How Does Logit Lens Work?\n",
    "\n",
    "- **Tokenization**\n",
    "    The input text, e.g.,\n",
    "\n",
    "    `\"We train GPT-3, an aut...\"`\n",
    "    is split into tokens:\n",
    "\n",
    "    `[\"We\", \" train\", \" GPT\", \"-\", \"3\", \",\", \" an\", \" aut\", ...]`\n",
    "\n",
    "    In practice, these are often not full words but parts of words or individual characters.\n",
    "\n",
    "- **Embedding**\n",
    "\n",
    "    Each token is transformed into a vector of numbers using the **embedding matrix**. This converts the text into a set of numerical vectors. In this way, each token becomes a point in a multidimensional space, where points that are close to each other represent similar meanings.\n",
    "\n",
    "- **Processing Through GPT Layers**\n",
    "\n",
    "    The vectors pass through successive **transformer layers**\n",
    "\n",
    "    Each layer adds new information, such as:\n",
    "\n",
    "    - Considering the context (what came before?),\n",
    "    - Recognizing linguistic structures (sentences, syntax),\n",
    "    - Developing meaning based on the surrounding tokens.\n",
    "\n",
    "    After each layer, we get **updated vectors** that increasingly \"understand\" the meaning of the text and what might come next.\n",
    "\n",
    "- **Standard Model Output**\n",
    "    At the end of the last layer, we get the final vector representing \"what should come next.\" This vector is transformed by multiplying it by the transpose of the embedding matrix, yielding logits. A softmax applied to these logits gives a probability distribution. The token with the highest probability is selected as the next one.\n",
    "\n",
    "- **Logit Lens: What Do We Do Differently?**\n",
    "\n",
    "    Logit Lens performs exactly **the same step**, but **for the vectors from earlier layers**.\n",
    "    This allows us to see how the model's \"types\" changed throughout the processing.\n",
    "\n",
    "    In the standard model operation, logits are computed **only at the end** — after the last layer.\n",
    "\n",
    "    **Logit Lens allows us to perform exactly the same step (multiplying by transposed matrix, softmax)**, but **for each intermediate layer**\n",
    "\n",
    "    This way, we can:\n",
    "\n",
    "    - See **what the model's predictions were** after each layer.\n",
    "    - Compare whether it **guessed correctly early on**, or if it **changed its mind only towards the end**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6092385",
   "metadata": {},
   "source": [
    "### Whar can we learn from reading Logit Lens visualisations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1bb55",
   "metadata": {},
   "source": [
    "TO DO \n",
    "dokoczenie jutro rano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9234a",
   "metadata": {},
   "source": [
    "### Interesting cases introduced in the article:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97e815",
   "metadata": {},
   "source": [
    "TO DO \n",
    "bo zle sie czuje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4fc73",
   "metadata": {},
   "source": [
    "byeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6250c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
